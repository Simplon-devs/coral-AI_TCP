{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from formatting import *\n",
    "\n",
    "# Paths to new pictures and corresponding annotations\n",
    "# before importing Sloth Json fix filepath in raw Json\n",
    "pictures_path = '/home/mdc/Desktop/Retraining/'\n",
    "sloth_json_path = './Retraining.json'\n",
    "\n",
    "# Don't change these\n",
    "annotations_path = '/media/mdc/Storage/data/Fragment detection/Individual Annotations/'\n",
    "outputDir = \"/media/mdc/Storage/data/Fragment detection/\"\n",
    "\n",
    "new_pictures_path = outputDir+\"all_pictures/\"\n",
    "\n",
    "picture_subs = {True: outputDir+\"train_pictures/\",\n",
    "                False: outputDir+\"val_pictures/\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Converts Sloth JSON Format to Pascal VOC (one annotation file per image).\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Removes mentions to images that don't have any annotation.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m add_new_annots(pictures_path, annotations_path, sloth_json_path, new_pictures_path)\n",
      "File \u001b[1;32mc:\\Users\\utilisateur\\Documents\\8- PROJET FINAL\\maldives-corals\\Fragment detection\\formatting.py:26\u001b[0m, in \u001b[0;36madd_new_annots\u001b[1;34m(pictures_path, annotation_path, sloth_json_path, new_pictures_path)\u001b[0m\n\u001b[0;32m     22\u001b[0m i_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m i_it \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data)):\n\u001b[1;32m---> 26\u001b[0m     \u001b[39mprint\u001b[39m(i_it\u001b[39m.\u001b[39;49mkeys)\n\u001b[0;32m     28\u001b[0m     pic \u001b[39m=\u001b[39m data[i_it]\n\u001b[0;32m     30\u001b[0m     filename \u001b[39m=\u001b[39m pic[\u001b[39m\"\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# Converts Sloth JSON Format to Pascal VOC (one annotation file per image).\n",
    "# Removes mentions to images that don't have any annotation.\n",
    "\n",
    "add_new_annots(pictures_path, annotations_path, sloth_json_path, new_pictures_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO annotations : Created 19890 annotations from 1103 images\n"
     ]
    }
   ],
   "source": [
    "# Converts Pascal VOC to COCO JSON. Splits into training and validation subsets (one annotation file each).\n",
    "# Copies images (only the ones with annotations) to subfolders.\n",
    "\n",
    "create_coco(new_pictures_path, annotations_path, outputDir, picture_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates TFRecords combining picture files and COCO annotations\n",
    "\n",
    "%run /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/dataset_tools/create_coco_tf_record.py \\\n",
    "    --train_image_dir=\"/media/mdc/Storage/data/Fragment detection/train_pictures\" \\\n",
    "    --train_annotations_file=\"/media/mdc/Storage/data/Fragment detection/COCO_train.json\" \\\n",
    "    --output_dir=\"/media/mdc/Storage/data/Fragment detection/TFRecords\" \\\n",
    "    --val_image_dir=\"/media/mdc/Storage/data/Fragment detection/val_pictures\" \\\n",
    "    --val_annotations_file=\"/media/mdc/Storage/data/Fragment detection/COCO_val.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON files handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge JSON files for retraining?\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "result = []\n",
    "for f in glob.glob('/home/mdc/Desktop/RunningFiles/JSON/*.json'):\n",
    "    with open(f, \"r\") as infile:\n",
    "        d = json.load(infile)\n",
    "        result.append(d)\n",
    "\n",
    "with open(\"/home/mdc/Desktop/Retraining/Retraining.json\", \"w\") as outfile:\n",
    "    json.dump(result, outfile, indent = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
